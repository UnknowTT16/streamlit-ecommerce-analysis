{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e759b5-69ea-4e65-bd85-59ba6ba90e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 1: 导入所有库并定义包含所有功能的最终版主分析函数\n",
    "# ==============================================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 解决 KMeans 内存泄漏警告 (必须在导入 KMeans 之前设置)\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "# 分析库\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "\n",
    "# 可视化库\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# NLP & 交互库\n",
    "from deep_translator import GoogleTranslator\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "# --- (关键修复) 这是一个修复了语法错误的、标准的多行函数 ---\n",
    "def sentiment_to_rating(sentiment):\n",
    "    if sentiment >= 0.5:\n",
    "        return 5\n",
    "    elif sentiment >= 0.05:\n",
    "        return 4\n",
    "    elif sentiment > -0.05:\n",
    "        return 3\n",
    "    elif sentiment > -0.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# --- 将所有分析步骤封装到主函数中 ---\n",
    "def run_analysis(sales_file, unesco_file, reviews_file):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"--- 正在使用销售文件: '{sales_file}' ---\")\n",
    "    if unesco_file: print(f\"--- 正在使用UNESCO文件: '{unesco_file}' ---\")\n",
    "    if reviews_file: print(f\"--- 正在使用评论文件: '{reviews_file}' ---\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # ==================== 1. 数据加载与清洗 ====================\n",
    "    try:\n",
    "        print(\"--- 正在加载与清洗数据 ---\")\n",
    "        amazon_df = pd.read_csv(sales_file, dtype={23: str}, on_bad_lines='skip')\n",
    "        if unesco_file:\n",
    "            unesco_df = pd.read_csv(unesco_file, encoding=\"utf-8-sig\", on_bad_lines='skip')\n",
    "        \n",
    "        # 智能重命名\n",
    "        if 'Total Sales' in amazon_df.columns: amazon_df.rename(columns={'Total Sales': 'Amount'}, inplace=True)\n",
    "        if 'Product' in amazon_df.columns: amazon_df.rename(columns={'Product': 'SKU'}, inplace=True)\n",
    "        if 'Qty' not in amazon_df.columns and 'Quantity' in amazon_df.columns: amazon_df.rename(columns={'Quantity': 'Qty'}, inplace=True)\n",
    "        if 'Order ID' not in amazon_df.columns and 'Order_ID' in amazon_df.columns: amazon_df.rename(columns={'Order_ID': 'Order ID'}, inplace=True)\n",
    "        \n",
    "        required_cols = [\"Amount\", \"Category\", \"Date\", \"Status\", \"SKU\", \"Order ID\", \"Qty\"]\n",
    "        if any(col not in amazon_df.columns for col in required_cols): raise ValueError(f\"文件 '{sales_file}' 缺少必需的列。\")\n",
    "        \n",
    "        amazon_df.dropna(subset=[\"Amount\", \"Category\", \"Date\"], inplace=True)\n",
    "        try:\n",
    "            amazon_df[\"Date\"] = pd.to_datetime(amazon_df[\"Date\"], format='%m-%d-%y')\n",
    "        except ValueError:\n",
    "            amazon_df[\"Date\"] = pd.to_datetime(amazon_df[\"Date\"], errors='coerce')\n",
    "            \n",
    "        amazon_df[\"Amount\"] = pd.to_numeric(amazon_df[\"Amount\"], errors='coerce')\n",
    "        valid_statuses = [\"Shipped\", \"Shipped - Delivered to Buyer\", \"Completed\", \"Pending\", \"Cancelled\"]\n",
    "        amazon_df = amazon_df[amazon_df[\"Status\"].isin(valid_statuses)]\n",
    "        amazon_df.dropna(subset=['Date', 'Amount', 'SKU', 'Order ID', 'Qty'], inplace=True)\n",
    "        \n",
    "        all_categories = amazon_df['Category'].unique()\n",
    "        non遗_products = amazon_df[amazon_df['Category'].str.contains('|'.join(all_categories), case=False, na=False)]\n",
    "        \n",
    "        print(\"✅ 数据加载和清洗完成！\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 处理数据时出错: {e}\"); return\n",
    "\n",
    "    # ==================== 2. 过滤与映射 ====================\n",
    "    print(\"\\n--- 正在进行过滤与映射 ---\")\n",
    "    if unesco_file:\n",
    "        keywords = ['craft', 'textile', 'embroidery', 'weaving', 'costume', 'dress', 'heritage product', 'handicraft']\n",
    "        relevant_unesco = unesco_df[unesco_df['Description EN'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "        print(f\"相关非遗数量: {len(relevant_unesco)}\")\n",
    "    print(f\"潜在非遗产品订单: {len(non遗_products)}\\n\")\n",
    "\n",
    "    # ==================== 3. 时间序列预测 (LSTM) ====================\n",
    "    print(\"\\n--- 🧠 正在进行 LSTM 深度学习预测 ---\")\n",
    "    try:\n",
    "        sales_ts = amazon_df.groupby('Date')['Amount'].sum().asfreq('D', fill_value=0)\n",
    "        sales_values = sales_ts.values.reshape(-1, 1)\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_values = scaler.fit_transform(sales_values)\n",
    "\n",
    "        def create_dataset(data, look_back=7):\n",
    "            X, y = [], []\n",
    "            for i in range(len(data) - look_back):\n",
    "                X.append(data[i:(i + look_back), 0])\n",
    "                y.append(data[i + look_back, 0])\n",
    "            return np.array(X), np.array(y)\n",
    "\n",
    "        look_back = 7\n",
    "        X, y = create_dataset(scaled_values, look_back)\n",
    "        X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        model = Sequential([Input(shape=(look_back, 1)), LSTM(50), Dense(1)])\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        \n",
    "        print(\"正在训练模型...\")\n",
    "        model.fit(X, y, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "        print(\"正在预测未来...\")\n",
    "        last_days_scaled = scaled_values[-look_back:]\n",
    "        current_input = np.reshape(last_days_scaled, (1, look_back, 1))\n",
    "        future_predictions_scaled = []\n",
    "        for _ in range(30):\n",
    "            next_pred_scaled = model.predict(current_input, verbose=0)\n",
    "            future_predictions_scaled.append(next_pred_scaled[0, 0])\n",
    "            new_pred_reshaped = np.reshape(next_pred_scaled, (1, 1, 1))\n",
    "            current_input = np.append(current_input[:, 1:, :], new_pred_reshaped, axis=1)\n",
    "        \n",
    "        future_predictions = scaler.inverse_transform(np.array(future_predictions_scaled).reshape(-1, 1))\n",
    "        \n",
    "        last_date = sales_ts.index[-1]\n",
    "        future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=30)\n",
    "        \n",
    "        fig_lstm = go.Figure()\n",
    "        fig_lstm.add_trace(go.Scatter(x=sales_ts.index, y=sales_ts.values, name='历史销售额', line=dict(color='royalblue', width=2), fill='tozeroy', fillcolor='rgba(65, 105, 225, 0.2)'))\n",
    "        fig_lstm.add_trace(go.Scatter(x=future_dates, y=future_predictions.flatten(), name='LSTM 预测销售额', line=dict(color='darkorange', dash='dash', width=2), fill='tozeroy', fillcolor='rgba(255, 140, 0, 0.2)'))\n",
    "        fig_lstm.update_layout(title='未来30天销售额深度学习预测 (LSTM模型)')\n",
    "        fig_lstm.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ LSTM 预测失败: {e}\")\n",
    "\n",
    "    # ==================== 4. 类别销售可视化 ====================\n",
    "    print(\"\\n--- 🛍️ 正在生成品类表现图 ---\")\n",
    "    category_means = non遗_products.groupby('Category')['Amount'].mean().sort_values(ascending=False).reset_index()\n",
    "    fig_bar = px.bar(category_means, x='Category', y='Amount', color='Category', text_auto='.2f', title='各产品类别平均销售额对比')\n",
    "    fig_bar.update_layout(width=800, height=500, showlegend=False); fig_bar.show()\n",
    "\n",
    "    # ==================== 5. 商品聚类分析 ====================\n",
    "    print(\"\\n--- 🔥 正在进行商品聚类分析 ---\")\n",
    "    try:\n",
    "        product_agg_df = amazon_df.groupby('SKU').agg(total_amount=('Amount', 'sum'), total_qty=('Qty', 'sum'), order_count=('Order ID', 'nunique')).reset_index()\n",
    "        features_to_cluster = ['total_amount', 'total_qty', 'order_count']; features = product_agg_df[features_to_cluster]\n",
    "        scaler = StandardScaler(); features_scaled = scaler.fit_transform(features)\n",
    "        kmeans = KMeans(n_clusters=3, n_init=10, random_state=42); product_agg_df.loc[:, 'cluster'] = kmeans.fit_predict(features_scaled)\n",
    "        cluster_summary = product_agg_df.groupby('cluster')[features_to_cluster].mean().sort_values(by='total_amount', ascending=False)\n",
    "        hot_product_cluster_id = cluster_summary.index[0]; hot_products = product_agg_df[product_agg_df['cluster'] == hot_product_cluster_id].sort_values(by='total_amount', ascending=False)\n",
    "        \n",
    "        print(\"\\n每个商品簇的特征均值:\")\n",
    "        display(cluster_summary)\n",
    "        print(\"\\n排名前10的热销商品:\")\n",
    "        display(hot_products.head(10))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 商品聚类失败: {e}\")\n",
    "\n",
    "    # ==================== 6. 情感分析 ====================\n",
    "    if reviews_file:\n",
    "        print(\"\\n--- 💬 正在进行情感分析 ---\")\n",
    "        try:\n",
    "            def find_review_column(df):\n",
    "                priority_cols = ['reviews.text', 'review_text', 'content', 'comment', 'review']\n",
    "                for p_col in priority_cols:\n",
    "                    if p_col in df.columns and df[p_col].dropna().astype(str).str.strip().any(): return p_col\n",
    "                object_cols = df.select_dtypes(include=['object']).columns\n",
    "                if not object_cols.empty:\n",
    "                    return max(object_cols, key=lambda col: df[col].dropna().astype(str).str.len().mean())\n",
    "                return None\n",
    "            \n",
    "            reviews_df = pd.read_csv(reviews_file)\n",
    "            review_column_name = find_review_column(reviews_df)\n",
    "            if review_column_name is None: raise ValueError(\"未能自动检测到文本列。\")\n",
    "            reviews_df.rename(columns={review_column_name: 'review_text'}, inplace=True)\n",
    "            reviews_df.dropna(subset=['review_text'], inplace=True)\n",
    "            analyzer = SentimentIntensityAnalyzer()\n",
    "            reviews_df['sentiment'] = reviews_df['review_text'].apply(lambda text: analyzer.polarity_scores(str(text))['compound'])\n",
    "            if 'rating' not in reviews_df.columns:\n",
    "                reviews_df['rating'] = reviews_df['sentiment'].apply(sentiment_to_rating)\n",
    "            \n",
    "            print(\"\\n情感分析结果预览:\")\n",
    "            display(reviews_df.head())\n",
    "            print(\"\\n高分(>=4星)与低分(<=2星)评论对比:\")\n",
    "            display(reviews_df[reviews_df['rating'] >= 4].head(3))\n",
    "            display(reviews_df[reviews_df['rating'] <= 2].head(3))\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 情感分析失败: {e}\")\n",
    "\n",
    "    # ==================== 7. 多语言翻译 ====================\n",
    "    if unesco_file:\n",
    "        print(\"\\n--- 🌍 正在进行非遗描述翻译 (仅前5条作为演示) ---\")\n",
    "        try:\n",
    "            def translate_text(text, target_lang):\n",
    "                if not isinstance(text, str) or not text.strip(): return \"\"\n",
    "                try: return GoogleTranslator(source='auto', target=target_lang).translate(text)\n",
    "                except: return text\n",
    "            target_languages = ['de', 'fr', 'zh-cn']; unesco_translated_df = unesco_df.head(5).copy()\n",
    "            for lang in target_languages:\n",
    "                column_name = f'Description_{lang.upper()}'\n",
    "                unesco_translated_df[column_name] = unesco_translated_df['Description EN'].apply(lambda x: translate_text(x, lang))\n",
    "            print(\"\\n翻译完成后的数据预览：\"); display(unesco_translated_df)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 翻译失败: {e}\")\n",
    "            \n",
    "    print(\"\\n--- ✨ 分析全部完成 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f9cbcd8-eb87-459e-a8f6-b0bf0019e78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ceb6bce81264acd9619ed64714da6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='选择销售文件:', options=('Amazon Sale Report.csv', 'amazon-fashion-800k+-user-r…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 2: 创建并显示交互式界面\n",
    "# ==============================================================================\n",
    "import os\n",
    "from ipywidgets import interactive_output, Dropdown, VBox\n",
    "\n",
    "# 扫描文件并创建下拉菜单\n",
    "csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "sales_report_options = [f for f in csv_files if 'amazon' in f.lower() or 'sales' in f.lower()]\n",
    "unesco_options = [f for f in csv_files if 'ich' in f.lower() or 'unesco' in f.lower()]\n",
    "reviews_options = [None] + [f for f in csv_files if 'review' in f.lower()]\n",
    "\n",
    "if not sales_report_options or not unesco_options:\n",
    "    print(\"错误：请确保销售文件和UNESCO文件都在当前目录中。\")\n",
    "else:\n",
    "    # 创建所有控件\n",
    "    sales_dropdown = Dropdown(options=sales_report_options, description='选择销售文件:')\n",
    "    unesco_dropdown = Dropdown(options=unesco_options, description='选择UNESCO文件:')\n",
    "    reviews_dropdown = Dropdown(options=reviews_options, description='选择评论文件 (可选):')\n",
    "\n",
    "    # 使用 interactive_output 将控件与函数输出分离\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    def on_value_change(change):\n",
    "        with output_area:\n",
    "            run_analysis(sales_dropdown.value, unesco_dropdown.value, reviews_dropdown.value)\n",
    "\n",
    "    # 监听控件值的变化\n",
    "    sales_dropdown.observe(on_value_change, names='value')\n",
    "    unesco_dropdown.observe(on_value_change, names='value')\n",
    "    reviews_dropdown.observe(on_value_change, names='value')\n",
    "\n",
    "    # 将控件和输出区域一起显示出来\n",
    "    display(VBox([sales_dropdown, unesco_dropdown, reviews_dropdown, output_area]))\n",
    "    \n",
    "    # 首次手动触发运行\n",
    "    on_value_change(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd233d-df4c-4941-abd3-ea4d335c36e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
