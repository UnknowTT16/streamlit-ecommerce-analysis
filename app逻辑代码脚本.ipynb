{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e759b5-69ea-4e65-bd85-59ba6ba90e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 1: å¯¼å…¥æ‰€æœ‰åº“å¹¶å®šä¹‰æœ€ç»ˆç‰ˆçš„ä¸»åˆ†æžå‡½æ•°\n",
    "# ==============================================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from deep_translator import GoogleTranslator\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# --- å°†æ‰€æœ‰åˆ†æžæ­¥éª¤å°è£…åˆ°ä¸»å‡½æ•°ä¸­ ---\n",
    "def run_analysis(sales_file, unesco_file, reviews_file):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"--- æ­£åœ¨ä½¿ç”¨é”€å”®æ–‡ä»¶: '{sales_file}' ---\")\n",
    "    print(f\"--- æ­£åœ¨ä½¿ç”¨UNESCOæ–‡ä»¶: '{unesco_file}' ---\")\n",
    "    if reviews_file: print(f\"--- æ­£åœ¨ä½¿ç”¨è¯„è®ºæ–‡ä»¶: '{reviews_file}' ---\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # ==================== 1. æ•°æ®åŠ è½½ä¸Žæ¸…æ´— ====================\n",
    "    try:\n",
    "        print(\"--- æ­£åœ¨åŠ è½½ä¸Žæ¸…æ´—æ•°æ® ---\")\n",
    "        amazon_df = pd.read_csv(sales_file, dtype={23: str}, on_bad_lines='skip')\n",
    "        unesco_df = pd.read_csv(unesco_file, encoding=\"utf-8-sig\", on_bad_lines='skip')\n",
    "        \n",
    "        # --- æ™ºèƒ½é‡å‘½åé€»è¾‘ä¿æŒä¸å˜ ---\n",
    "        if 'Total Sales' in amazon_df.columns: amazon_df.rename(columns={'Total Sales': 'Amount'}, inplace=True)\n",
    "        if 'Product' in amazon_df.columns: amazon_df.rename(columns={'Product': 'SKU'}, inplace=True)\n",
    "        if 'Qty' not in amazon_df.columns and 'Quantity' in amazon_df.columns: amazon_df.rename(columns={'Quantity': 'Qty'}, inplace=True)\n",
    "        if 'Order ID' not in amazon_df.columns and 'Order_ID' in amazon_df.columns: amazon_df.rename(columns={'Order_ID': 'Order ID'}, inplace=True)\n",
    "        \n",
    "        required_cols = [\"Amount\", \"Category\", \"Date\", \"Status\", \"SKU\", \"Order ID\", \"Qty\"]\n",
    "        if any(col not in amazon_df.columns for col in required_cols): raise ValueError(f\"æ–‡ä»¶ '{sales_file}' ç¼ºå°‘å¿…éœ€çš„åˆ—ã€‚\")\n",
    "        \n",
    "        amazon_df.dropna(subset=[\"Amount\", \"Category\", \"Date\"], inplace=True)\n",
    "        \n",
    "        # --- (å…³é”®ä¿®æ”¹) ä½¿ç”¨ try-except æ¥å¤„ç†æ—¥æœŸæ ¼å¼ ---\n",
    "        try:\n",
    "            # ä¼˜å…ˆå°è¯•ä½¿ç”¨æ—§æ–‡ä»¶çš„é«˜æ•ˆæ ¼å¼\n",
    "            amazon_df[\"Date\"] = pd.to_datetime(amazon_df[\"Date\"], format='%m-%d-%y')\n",
    "            print(\"æ—¥æœŸæ ¼å¼åŒ¹é…: MM-DD-YY\")\n",
    "        except ValueError:\n",
    "            # å¦‚æžœå¤±è´¥ï¼Œåˆ™å›žé€€åˆ°è‡ªåŠ¨è§£æžï¼Œè¿™æ ·å¯ä»¥å…¼å®¹æ–°æ–‡ä»¶æ ¼å¼\n",
    "            print(\"æ—¥æœŸæ ¼å¼ä¸åŒ¹é… MM-DD-YYï¼Œå›žé€€åˆ°è‡ªåŠ¨è§£æž...\")\n",
    "            amazon_df[\"Date\"] = pd.to_datetime(amazon_df[\"Date\"], errors='coerce')\n",
    "            \n",
    "        amazon_df[\"Amount\"] = pd.to_numeric(amazon_df[\"Amount\"], errors='coerce')\n",
    "        valid_statuses = [\"Shipped\", \"Shipped - Delivered to Buyer\", \"Completed\", \"Pending\", \"Cancelled\"]\n",
    "        amazon_df = amazon_df[amazon_df[\"Status\"].isin(valid_statuses)]\n",
    "        amazon_df.dropna(subset=['Date', 'Amount', 'SKU', 'Order ID', 'Qty'], inplace=True)\n",
    "        \n",
    "        print(\"âœ… æ•°æ®åŠ è½½å’Œæ¸…æ´—å®Œæˆï¼\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å¤„ç†æ•°æ®æ—¶å‡ºé”™: {e}\"); return\n",
    "        \n",
    "    # (åŽç»­çš„æ‰€æœ‰åˆ†æžæ¨¡å—ä»£ç ä¿æŒä¸å˜)\n",
    "    # ...\n",
    "    # ==================== 2. è¿‡æ»¤ä¸Žæ˜ å°„ ====================\n",
    "    print(\"\\n--- æ­£åœ¨è¿›è¡Œè¿‡æ»¤ä¸Žæ˜ å°„ ---\")\n",
    "    keywords = ['craft', 'textile', 'embroidery', 'weaving', 'costume', 'dress', 'heritage product', 'handicraft']\n",
    "    relevant_unesco = unesco_df[unesco_df['Description EN'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "    all_categories = amazon_df['Category'].unique()\n",
    "    noné—_products = amazon_df[amazon_df['Category'].str.contains('|'.join(all_categories), case=False, na=False)]\n",
    "    print(f\"ç›¸å…³éžé—æ•°é‡: {len(relevant_unesco)}\")\n",
    "    print(f\"æ½œåœ¨éžé—äº§å“è®¢å•: {len(noné—_products)}\\n\")\n",
    "\n",
    "    # ==================== 3. æ—¶é—´åºåˆ—é¢„æµ‹ ====================\n",
    "    print(\"\\n--- ðŸ“Š æ­£åœ¨ç”Ÿæˆé”€å”®é¢„æµ‹å›¾ ---\")\n",
    "    sales_ts = amazon_df.groupby('Date')['Amount'].sum().asfreq('D', fill_value=0)\n",
    "    model = ARIMA(sales_ts, order=(5, 1, 0)); model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=30)\n",
    "    fig_ts = go.Figure()\n",
    "    fig_ts.add_trace(go.Scatter(x=sales_ts.index, y=sales_ts, name='åŽ†å²é”€å”®é¢', fill='tozeroy'))\n",
    "    fig_ts.add_trace(go.Scatter(x=forecast.index, y=forecast, name='é¢„æµ‹é”€å”®é¢', fill='tozeroy'))\n",
    "    fig_ts.update_layout(title='æœªæ¥30å¤©é”€å”®é¢äº¤äº’å¼é¢„æµ‹ (ARIMAæ¨¡åž‹)')\n",
    "    fig_ts.show()\n",
    "\n",
    "    # ==================== 4. ç±»åˆ«é”€å”®å¯è§†åŒ– ====================\n",
    "    print(\"\\n--- ðŸ›ï¸ æ­£åœ¨ç”Ÿæˆå“ç±»è¡¨çŽ°å›¾ ---\")\n",
    "    category_means = noné—_products.groupby('Category')['Amount'].mean().sort_values(ascending=False).reset_index()\n",
    "    fig_bar = px.bar(category_means, x='Category', y='Amount', color='Category', text_auto='.2f', title='å„äº§å“ç±»åˆ«å¹³å‡é”€å”®é¢å¯¹æ¯”')\n",
    "    fig_bar.update_layout(width=800, height=500, showlegend=False)\n",
    "    fig_bar.show()\n",
    "\n",
    "    # ==================== 5. å•†å“èšç±»åˆ†æž ====================\n",
    "    print(\"\\n--- ðŸ”¥ æ­£åœ¨è¿›è¡Œå•†å“èšç±»åˆ†æž ---\")\n",
    "    product_agg_df = amazon_df.groupby('SKU').agg(total_amount=('Amount', 'sum'), total_qty=('Qty', 'sum'), order_count=('Order ID', 'nunique')).reset_index()\n",
    "    features_to_cluster = ['total_amount', 'total_qty', 'order_count']; features = product_agg_df[features_to_cluster]\n",
    "    scaler = StandardScaler(); features_scaled = scaler.fit_transform(features)\n",
    "    kmeans = KMeans(n_clusters=3, n_init=10, random_state=42); product_agg_df.loc[:, 'cluster'] = kmeans.fit_predict(features_scaled)\n",
    "    cluster_summary = product_agg_df.groupby('cluster')[features_to_cluster].mean().sort_values(by='total_amount', ascending=False)\n",
    "    hot_product_cluster_id = cluster_summary.index[0]; hot_products = product_agg_df[product_agg_df['cluster'] == hot_product_cluster_id].sort_values(by='total_amount', ascending=False)\n",
    "    print(\"\\næ¯ä¸ªå•†å“ç°‡çš„ç‰¹å¾å‡å€¼:\"); display(cluster_summary)\n",
    "    print(\"\\næŽ’åå‰10çš„çƒ­é”€å•†å“:\"); display(hot_products.head(10))\n",
    "    \n",
    "    # ==================== 6. (å¯é€‰) æƒ…æ„Ÿåˆ†æž ====================\n",
    "    if reviews_file:\n",
    "        print(\"\\n--- ðŸ’¬ æ­£åœ¨è¿›è¡Œæƒ…æ„Ÿåˆ†æž ---\")\n",
    "        try:\n",
    "            def find_review_column(df):\n",
    "                priority_cols = ['reviews.text', 'review_text', 'content', 'comment', 'review']\n",
    "                for p_col in priority_cols:\n",
    "                    if p_col in df.columns and df[p_col].dropna().astype(str).str.strip().any(): return p_col\n",
    "                object_cols = df.select_dtypes(include=['object']).columns\n",
    "                if not object_cols.empty:\n",
    "                    return max(object_cols, key=lambda col: df[col].dropna().astype(str).str.len().mean())\n",
    "                return None\n",
    "            def sentiment_to_rating(sentiment):\n",
    "                if sentiment >= 0.5: return 5\n",
    "                elif sentiment >= 0.05: return 4\n",
    "                elif sentiment > -0.05: return 3\n",
    "                elif sentiment > -0.5: return 2\n",
    "                else: return 1\n",
    "            reviews_df = pd.read_csv(reviews_file)\n",
    "            review_column_name = find_review_column(reviews_df)\n",
    "            if review_column_name is None: raise ValueError(\"æœªèƒ½è‡ªåŠ¨æ£€æµ‹åˆ°æ–‡æœ¬åˆ—ã€‚\")\n",
    "            \n",
    "            reviews_df.rename(columns={review_column_name: 'review_text'}, inplace=True)\n",
    "            reviews_df.dropna(subset=['review_text'], inplace=True)\n",
    "            \n",
    "            analyzer = SentimentIntensityAnalyzer()\n",
    "            reviews_df['sentiment'] = reviews_df['review_text'].apply(lambda text: analyzer.polarity_scores(str(text))['compound'])\n",
    "            \n",
    "            if 'rating' not in reviews_df.columns:\n",
    "                reviews_df['rating'] = reviews_df['sentiment'].apply(sentiment_to_rating)\n",
    "            \n",
    "            print(\"\\næƒ…æ„Ÿåˆ†æžç»“æžœé¢„è§ˆ:\")\n",
    "            display(reviews_df.head())\n",
    "            print(\"\\né«˜åˆ†(>=4æ˜Ÿ)ä¸Žä½Žåˆ†(<=2æ˜Ÿ)è¯„è®ºå¯¹æ¯”:\")\n",
    "            display(reviews_df[reviews_df['rating'] >= 4].head(3))\n",
    "            display(reviews_df[reviews_df['rating'] <= 2].head(3))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"æƒ…æ„Ÿåˆ†æžå¤±è´¥: {e}\")\n",
    "\n",
    "    # ==================== 7. (å¯é€‰) å¤šè¯­è¨€ç¿»è¯‘ ====================\n",
    "    print(\"\\n--- ðŸŒ æ­£åœ¨è¿›è¡Œéžé—æè¿°ç¿»è¯‘ (ä»…å‰5æ¡ä½œä¸ºæ¼”ç¤º) ---\")\n",
    "    def translate_text(text, target_lang):\n",
    "        if not isinstance(text, str) or not text.strip(): return \"\"\n",
    "        try: return GoogleTranslator(source='auto', target=target_lang).translate(text)\n",
    "        except: return text\n",
    "    target_languages = ['de', 'fr']; unesco_translated_df = unesco_df.head(5).copy()\n",
    "    for lang in target_languages:\n",
    "        column_name = f'Description_{lang.upper()}'\n",
    "        unesco_translated_df[column_name] = unesco_translated_df['Description EN'].apply(lambda x: translate_text(x, lang))\n",
    "    print(\"\\nç¿»è¯‘å®ŒæˆåŽçš„æ•°æ®é¢„è§ˆï¼š\"); display(unesco_translated_df)\n",
    "    \n",
    "    print(\"\\n--- âœ¨ åˆ†æžå…¨éƒ¨å®Œæˆ ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f9cbcd8-eb87-459e-a8f6-b0bf0019e78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e60ad477d64b90a23f046d53f85848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='é€‰æ‹©é”€å”®æ–‡ä»¶:', options=('Amazon Sale Report.csv', 'amazon-fashion-800k+-user-râ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 2: åˆ›å»ºå¹¶æ˜¾ç¤ºäº¤äº’å¼ç•Œé¢\n",
    "# ==============================================================================\n",
    "import os\n",
    "from ipywidgets import interactive_output, Dropdown, VBox\n",
    "\n",
    "# 1. æ‰«ææ–‡ä»¶å¹¶åˆ›å»ºä¸‹æ‹‰èœå•\n",
    "csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "sales_report_options = [f for f in csv_files if 'amazon' in f.lower() or 'sales' in f.lower()]\n",
    "unesco_options = [f for f in csv_files if 'ich' in f.lower() or 'unesco' in f.lower()]\n",
    "reviews_options = [None] + [f for f in csv_files if 'review' in f.lower()]\n",
    "\n",
    "if not sales_report_options or not unesco_options:\n",
    "    print(\"é”™è¯¯ï¼šè¯·ç¡®ä¿é”€å”®æ–‡ä»¶å’ŒUNESCOæ–‡ä»¶éƒ½åœ¨å½“å‰ç›®å½•ä¸­ã€‚\")\n",
    "else:\n",
    "    # 2. åˆ›å»ºæ‰€æœ‰æŽ§ä»¶\n",
    "    sales_dropdown = Dropdown(options=sales_report_options, description='é€‰æ‹©é”€å”®æ–‡ä»¶:')\n",
    "    unesco_dropdown = Dropdown(options=unesco_options, description='é€‰æ‹©UNESCOæ–‡ä»¶:')\n",
    "    reviews_dropdown = Dropdown(options=reviews_options, description='é€‰æ‹©è¯„è®ºæ–‡ä»¶ (å¯é€‰):')\n",
    "\n",
    "    # 3. ä½¿ç”¨ interactive_output å°†æŽ§ä»¶ä¸Žå‡½æ•°è¾“å‡ºåˆ†ç¦»\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    def on_value_change(change):\n",
    "        with output_area:\n",
    "            run_analysis(sales_dropdown.value, unesco_dropdown.value, reviews_dropdown.value)\n",
    "\n",
    "    # 4. ç›‘å¬æŽ§ä»¶å€¼çš„å˜åŒ–\n",
    "    sales_dropdown.observe(on_value_change, names='value')\n",
    "    unesco_dropdown.observe(on_value_change, names='value')\n",
    "    reviews_dropdown.observe(on_value_change, names='value')\n",
    "\n",
    "    # 5. å°†æŽ§ä»¶å’Œè¾“å‡ºåŒºåŸŸä¸€èµ·æ˜¾ç¤ºå‡ºæ¥\n",
    "    display(VBox([sales_dropdown, unesco_dropdown, reviews_dropdown, output_area]))\n",
    "    \n",
    "    # 6. é¦–æ¬¡æ‰‹åŠ¨è§¦å‘è¿è¡Œ\n",
    "    on_value_change(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd233d-df4c-4941-abd3-ea4d335c36e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
